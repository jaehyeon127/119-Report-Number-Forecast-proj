import pandas as pd
import numpy as np
import joblib
import os
import sys

# ê²½ë¡œ ì„¤ì •ì„ ìœ„í•´ src í´ë”ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

from src.pre_esm_crash import load_data, preprocess_data, encode_features, preprocess_people_data, preprocess_traffic_data

RESULTS_DIR = 'predictions'
MODEL_DIR = 'models'

BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(BASE_DIR, '..', 'data')
TEST_CALL_PATH = os.path.join(DATA_DIR, 'call119_test.csv')
TEST_CAT_PATH = os.path.join(DATA_DIR, 'cat119_test.csv')
TEST_ALERT_PATH = os.path.join(DATA_DIR, '2024_weather_alert.csv')
TEST_PEOPLE_PATH = os.path.join(DATA_DIR, '2023_people.csv')


TEST_TRAFFIC_FILES_INFO = [
    {'path': os.path.join(DATA_DIR, 'Report_2023.csv'), 'year': 2023},
    {'path': os.path.join(DATA_DIR, 'Report_2024.csv'), 'year': 2024},
]
# ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ìŠ¤íƒœí‚¹ ëª¨ë¸ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
MODEL_PATH = os.path.join(MODEL_DIR, 'optimized_stacking_regressor_alert.pkl')
MODEL_COLUMNS_PATH = os.path.join(MODEL_DIR, 'ml_model_columns_crash.pkl')
SCALER_PATH = os.path.join(MODEL_DIR, 'ml_scaler_crash.pkl')


def predict():
    """
    í•™ìŠµëœ Stacking ì•™ìƒë¸” ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    """
    print("--- ì•™ìƒë¸” ëª¨ë¸ ì˜ˆì¸¡ ì ˆì°¨ ì‹œì‘ ---")
    os.makedirs(RESULTS_DIR, exist_ok=True)

    # 1. ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸°(ì»¬ëŸ¼, ìŠ¤ì¼€ì¼ëŸ¬) ë¡œë“œ
    print("\n1. í•™ìŠµëœ Stacking ëª¨ë¸, ì»¬ëŸ¼, ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ...")
    try:
        model = joblib.load(MODEL_PATH)
        model_columns = joblib.load(MODEL_COLUMNS_PATH)
        scaler = joblib.load(SCALER_PATH)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(MODEL_PATH)}")
        print(f"   - ì˜ˆìƒ í”¼ì²˜ ìˆ˜: {len(model_columns)}")
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ê´€ë ¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'main_esm.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì„¸ìš”.")
        print(f"   - ëˆ„ë½ëœ íŒŒì¼: {e.filename}")
        return

    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print("\n2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ...")
    try:
        call119_test_df, cat119_test_df = load_data(TEST_CALL_PATH, TEST_CAT_PATH)

        # ê¸°ìƒ íŠ¹ë³´ ë°ì´í„° ë¡œë“œ
        alert_test_df = pd.DataFrame()
        if os.path.exists(TEST_ALERT_PATH):
            try:

                for encoding in ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']:
                    try:
                        alert_test_df = pd.read_csv(TEST_ALERT_PATH, encoding=encoding, index_col=False)
                        print(f"âœ… í…ŒìŠ¤íŠ¸ìš© ê¸°ìƒíŠ¹ë³´ ë°ì´í„° ë¡œë“œ: {os.path.basename(TEST_ALERT_PATH)}")
                        break
                    except (UnicodeDecodeError, pd.errors.ParserError):
                        continue
                if alert_test_df.empty:
                    print(f"âŒ '{os.path.basename(TEST_ALERT_PATH)}' íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ìš© ê¸°ìƒíŠ¹ë³´ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                alert_test_df = pd.DataFrame()
        else:
            print("âš ï¸ í…ŒìŠ¤íŠ¸ìš© ê¸°ìƒíŠ¹ë³´ íŒŒì¼ì´ ì—†ì–´, íŠ¹ë³´ ì—†ìŒì„ ê°€ì •í•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤.")
            alert_test_df = pd.DataFrame()

        # ì¸êµ¬ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        people_test_df = pd.DataFrame()
        if os.path.exists(TEST_PEOPLE_PATH):
            try:
                people_test_df = preprocess_people_data(TEST_PEOPLE_PATH)
                print(f"âœ… í…ŒìŠ¤íŠ¸ìš© ì¸êµ¬ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬: {os.path.basename(TEST_PEOPLE_PATH)}")
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ìš© ì¸êµ¬ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì¸êµ¬ ë°ì´í„° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
                people_test_df = pd.DataFrame()
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ìš© ì¸êµ¬ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {TEST_PEOPLE_PATH}. ì¸êµ¬ ë°ì´í„° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        traffic_dfs = []
        for file_info in TEST_TRAFFIC_FILES_INFO:
            if os.path.exists(file_info['path']):
                try:
                    df_year = preprocess_traffic_data(file_info['path'], file_info['year'])
                    traffic_dfs.append(df_year)
                except Exception as e:
                    print(f"âŒ {file_info['year']}ë…„ êµí†µì‚¬ê³  ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                print(f"âš ï¸  {file_info['year']}ë…„ êµí†µì‚¬ê³  ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_info['path']}")

        if traffic_dfs:
            traffic_test_df = pd.concat(traffic_dfs, ignore_index=True)
            print(f"âœ… í…ŒìŠ¤íŠ¸ìš© êµí†µì‚¬ê³  ë°ì´í„° í†µí•© ì™„ë£Œ: {traffic_test_df.shape}")
        else:
            traffic_test_df = pd.DataFrame()
            print("âš ï¸ ì²˜ë¦¬í•  êµí†µì‚¬ê³  ë°ì´í„°ê°€ ì—†ì–´, í•´ë‹¹ í”¼ì²˜ ì—†ì´ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   - ëˆ„ë½ëœ íŒŒì¼: {e.filename}")
        return
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return


    print("\n3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¸ì½”ë”©...")
    try:
        # ì „ì²˜ë¦¬: weather_alertì™€ people ë°ì´í„° ì „ë‹¬
        processed_test_df = preprocess_data(
            call119_test_df.copy(),
            cat119_test_df.copy(),
            alert_test_df,
            traffic_test_df,
            people_test_df
        )
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {processed_test_df.shape}")

        # ì¸ì½”ë”©: í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ í•¨ìˆ˜ì™€ ë™ì¼í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        final_test_df = encode_features(processed_test_df)
        print(f"âœ… ì¸ì½”ë”© ì™„ë£Œ: {final_test_df.shape}")

    except Exception as e:
        print(f"âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return

        # ID ì»¬ëŸ¼ ì²˜ë¦¬ (ì œì¶œìš©)
    submission_df = pd.DataFrame()
    # 'id' ì»¬ëŸ¼ì´ ì›ë³¸ ë°ì´í„°ì— ìˆëŠ”ì§€ í™•ì¸ (clean_column_namesë¡œ ì†Œë¬¸ìí™”ë¨)
    if 'id' in final_test_df.columns:
        submission_df['ID'] = final_test_df['id']
    elif 'ID' in final_test_df.columns:  # ì›ë³¸ì´ ëŒ€ë¬¸ìì¼ ê²½ìš°ë„ ëŒ€ë¹„
        submission_df['ID'] = final_test_df['ID']
    else:
        # ID ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, ìˆœì°¨ì ì¸ ì„ì‹œ ID ìƒì„±
        submission_df['ID'] = ["TEST_" + str(i) for i in range(len(final_test_df))]
        print(f"âš ï¸ ID ì»¬ëŸ¼ì´ ì—†ì–´ ì„ì‹œ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì˜ˆ: TEST_0, TEST_1...)")

    # 4. í”¼ì²˜ ì •ë ¬ ë° ìŠ¤ì¼€ì¼ë§
    print("\n4. í”¼ì²˜ ì •ë ¬ ë° ìŠ¤ì¼€ì¼ë§ ì ìš©...")
    # 4-1. í›ˆë ¨ ë°ì´í„°ì˜ ì»¬ëŸ¼ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ë§ì¶”ê³ , ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
    X_test = final_test_df.reindex(columns=model_columns, fill_value=0)
    print(f"âœ… í”¼ì²˜ ì •ë ¬ ì™„ë£Œ. ìµœì¢… í”¼ì²˜ ìˆ˜: {X_test.shape[1]}")

    # 4-2. ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜(transform)í•©ë‹ˆë‹¤.
    try:

        numerical_cols_from_scaler = scaler.feature_names_in_
        cols_to_scale = [col for col in numerical_cols_from_scaler if col in X_test.columns]

        if cols_to_scale:

            X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])
            print(f"âœ… ìŠ¤ì¼€ì¼ë§ ì ìš© ì™„ë£Œ: {len(cols_to_scale)}ê°œ ì»¬ëŸ¼")
        else:
            print("âš ï¸ ìŠ¤ì¼€ì¼ë§í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜, ìŠ¤ì¼€ì¼ëŸ¬ê°€ í•™ìŠµëœ ì»¬ëŸ¼ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ìŠ¤ì¼€ì¼ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return

        # 5. ì˜ˆì¸¡ ìˆ˜í–‰
    print("\n5. ì˜ˆì¸¡ ìˆ˜í–‰...")
    try:
        predictions = model.predict(X_test)
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)} ê±´")
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return

    # 6. ê²°ê³¼ í›„ì²˜ë¦¬ ë° ì €ì¥
    print("\n6. ê²°ê³¼ ì €ì¥...")
    # ì˜ˆì¸¡ê°’ì€ 0 ì´ìƒì´ì–´ì•¼ í•˜ê³ , ì •ìˆ˜ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    predictions_cleaned = np.maximum(0, predictions).round().astype(int)
    submission_df['prediction'] = predictions_cleaned

    output_path = os.path.join(RESULTS_DIR, 'submission_pe10_crash.csv')
    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"âœ… ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
    print(f"   - ì´ ì˜ˆì¸¡ ê±´ìˆ˜: {len(predictions_cleaned)}")
    print(f"   - ì˜ˆì¸¡ê°’ ë²”ìœ„: {predictions_cleaned.min()} ~ {predictions_cleaned.max()}")
    print(f"   - ì˜ˆì¸¡ê°’ í‰ê· : {predictions_cleaned.mean():.2f}")


if __name__ == '__main__':
    predict()
