# main.py - 119 ì‹ ê³  ê±´ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ (ëª¨ë“  ê¸°ëŠ¥ ë° ìƒì„¸ ë¡œê·¸ ìœ ì§€ ìµœì¢…ë³¸)

import pandas as pd
import os
import sys
import joblib
import argparse
from datetime import datetime

# ê²½ë¡œ ì„¤ì •ì„ ìœ„í•´ src í´ë”ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

# í•„ìš”í•œ ëª¨ë“  í•¨ìˆ˜ ì„í¬íŠ¸
from src.pre_esm_crash import (load_data, preprocess_data, encode_features,
                         split_data_time_series, preprocess_people_data,
                         preprocess_traffic_data)
from src.train_ml_model_crash import run_stacking_model


class Config:
    """í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    BASE_DIR = os.path.dirname(__file__)
    DATA_DIR = os.path.join(BASE_DIR, '..', 'data')
    RESULTS_DIR = os.path.join(BASE_DIR, 'results')
    MODELS_DIR = os.path.join(BASE_DIR, 'models')

    # ì…ë ¥ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    CALL119_TRAIN_PATH = os.path.join(DATA_DIR, 'call119_train1.csv')
    CAT119_TRAIN_PATH = os.path.join(DATA_DIR, 'cat119_train1.csv')
    ALERT_TRAIN_PATH = os.path.join(DATA_DIR, 'weather_alert.csv')
    PEOPLE_TRAIN_PATH = os.path.join(DATA_DIR, '2023_people.csv')

    TRAFFIC_FILES_INFO = [
        {'path': os.path.join(DATA_DIR, 'Report_2020.csv'), 'year': 2020},
        {'path': os.path.join(DATA_DIR, 'Report_2021.csv'), 'year': 2021},
        {'path': os.path.join(DATA_DIR, 'Report_2022.csv'), 'year': 2022},
        {'path': os.path.join(DATA_DIR, 'Report_2023.csv'), 'year': 2023},
    ]

    # ëª¨ë¸ ë° ì•„í‹°íŒ©íŠ¸ ì €ì¥ ê²½ë¡œ
    STACKING_MODEL_PATH = os.path.join(MODELS_DIR, 'optimized_stacking_regressor_crash.pkl')
    MODEL_COLUMNS_PATH = os.path.join(MODELS_DIR, 'ml_model_columns_crash.pkl')
    SCALER_PATH = os.path.join(MODELS_DIR, 'ml_scaler_crash.pkl')

    # ëª¨ë¸ í•™ìŠµ íŒŒë¼ë¯¸í„°
    TARGET_COLUMN = 'call_count'
    TRAIN_RATIO = 0.7
    VAL_RATIO = 0.15
    RANDOM_STATE = 42


def setup_directories():
    """ê²°ê³¼ ë° ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    for directory in [Config.RESULTS_DIR, Config.MODELS_DIR]:
        os.makedirs(directory, exist_ok=True)


def check_data_files():
    """ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    required_files = [
        (Config.CALL119_TRAIN_PATH, 'call119 í›ˆë ¨ ë°ì´í„°'),
        (Config.CAT119_TRAIN_PATH, 'cat119 í›ˆë ¨ ë°ì´í„°'),
    ]
    for file_info in Config.TRAFFIC_FILES_INFO:
        if os.path.exists(file_info['path']):
            required_files.append((file_info['path'], f"{file_info['year']}ë…„ êµí†µì‚¬ê³  ë°ì´í„°"))

    all_files_exist = True
    for file_path, description in required_files:
        if not os.path.exists(file_path):
            print(f"   - âŒ '{description}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            all_files_exist = False
        else:
            print(f"   - âœ… '{description}' íŒŒì¼ í™•ì¸ ì™„ë£Œ.")
    return all_files_exist


def print_project_info():
    """í”„ë¡œì íŠ¸ ì •ë³´ ì¶œë ¥"""
    print("=" * 80)
    print("ğŸš¨ 119 ì‹ ê³  ê±´ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ (ëª¨ë“  ê¸°ëŠ¥ ë° ìƒì„¸ ë¡œê·¸ ìœ ì§€) ğŸš¨")
    print("=" * 80)


def load_and_validate_data():
    """ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ê²€ì¦"""
    call_df, cat_df = load_data(Config.CALL119_TRAIN_PATH, Config.CAT119_TRAIN_PATH)

    alert_df = pd.read_csv(Config.ALERT_TRAIN_PATH, encoding='utf-8') if os.path.exists(
        Config.ALERT_TRAIN_PATH) else pd.DataFrame()
    print(f"   - ê¸°ìƒíŠ¹ë³´ ë°ì´í„° ë¡œë“œ: {alert_df.shape}")

    people_df = preprocess_people_data(Config.PEOPLE_TRAIN_PATH) if os.path.exists(
        Config.PEOPLE_TRAIN_PATH) else pd.DataFrame()

    traffic_dfs = [preprocess_traffic_data(f['path'], f['year']) for f in Config.TRAFFIC_FILES_INFO if
                   os.path.exists(f['path'])]
    traffic_df = pd.concat(traffic_dfs, ignore_index=True) if traffic_dfs else pd.DataFrame()
    print(f"   - í†µí•© êµí†µì‚¬ê³  ë°ì´í„° ìƒì„±: {traffic_df.shape}")

    return call_df, cat_df, alert_df, traffic_df, people_df


def preprocess_and_encode_data(call119_df, cat119_df, alert_df, traffic_df, people_df):
    """ë°ì´í„° í†µí•© ì „ì²˜ë¦¬ ë° ì¸ì½”ë”©"""
    processed_df = preprocess_data(call119_df, cat119_df, alert_df, traffic_df, people_df)
    final_df = encode_features(processed_df)
    return final_df


def split_and_scale_data(final_df):
    """ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§"""
    return split_data_time_series(
        final_df, Config.TARGET_COLUMN, Config.TRAIN_RATIO, Config.VAL_RATIO
    )


def save_preprocessing_artifacts(X_train, scaler):
    """ì „ì²˜ë¦¬ ê´€ë ¨ ì•„í‹°íŒ©íŠ¸ ì €ì¥"""
    joblib.dump(X_train.columns, Config.MODEL_COLUMNS_PATH)
    joblib.dump(scaler, Config.SCALER_PATH)


def train_model(X_train, X_val, X_test, y_train, y_val, y_test):
    """ëª¨ë¸ í•™ìŠµ"""
    return run_stacking_model(
        X_train, X_val, X_test, y_train, y_val, y_test,
        results_dir=Config.RESULTS_DIR,
        models_dir=Config.MODELS_DIR
    )


def print_completion_summary(results):
    """í”„ë¡œì íŠ¸ ì™„ë£Œ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ‰ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ì™„ë£Œ!")
    print("=" * 80)
    if results and 'metrics' in results:
        metrics = results['metrics']
        print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸):")
        print(f"   - MAE: {metrics['MAE']:.4f}, RMSE: {metrics['RMSE']:.4f}, RÂ²: {metrics['R2']:.4f}")

    print("\nğŸ“ ìƒì„±ëœ ì£¼ìš” íŒŒì¼:")
    print(f"   - ëª¨ë¸: {Config.STACKING_MODEL_PATH}")
    print(f"   - ê²°ê³¼ë¶„ì„ ê·¸ë˜í”„ ë° ìš”ì•½: '{Config.RESULTS_DIR}' í´ë”")

    print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: 'predict_esm.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
    print("=" * 80)


def main(args=None):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print_project_info()

        print("1. ë””ë ‰í† ë¦¬ ì„¤ì • í™•ì¸...")
        setup_directories()
        print("âœ… ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ.")

        print("\n2. ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸...")
        if not check_data_files():
            print("\nâŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì´ ì—†ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return False

        print("\n3. ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ë¡œë“œ ë° ê°œë³„ ì „ì²˜ë¦¬ ì‹œì‘")
        print("-" * 50)
        datasets = load_and_validate_data()
        call_df, cat_df, alert_df, traffic_df, people_df = datasets
        print("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")

        print("\n4. ë°ì´í„° í†µí•© ì „ì²˜ë¦¬ ë° ì¸ì½”ë”© ì‹œì‘")
        print("-" * 50)
        final_df = preprocess_and_encode_data(*datasets)
        print("âœ… ì „ì²˜ë¦¬ ë° ì¸ì½”ë”© ì™„ë£Œ.")

        print("\n5. ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§ ì‹œì‘")
        print("-" * 50)
        X_train, X_val, X_test, y_train, y_val, y_test, scaler = split_and_scale_data(final_df)
        print("âœ… ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ.")

        print("\n6. ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸(ì»¬ëŸ¼, ìŠ¤ì¼€ì¼ëŸ¬) ì €ì¥ ì‹œì‘")
        print("-" * 50)
        save_preprocessing_artifacts(X_train, scaler)
        print("âœ… ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ.")

        print("\n7. ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("-" * 50)
        results = train_model(X_train, X_val, X_test, y_train, y_val, y_test)
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")

        print_completion_summary(results)
        return True

    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        import traceback
        traceback.print_exc()
        return False


def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='119 ì‹ ê³  ê±´ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ')
    return parser.parse_args()


if __name__ == '__main__':
    args = parse_arguments()
    success = main(args)
    sys.exit(0 if success else 1)